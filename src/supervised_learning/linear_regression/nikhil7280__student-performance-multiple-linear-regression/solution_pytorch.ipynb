{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b83f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff818718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91dbf92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(pd.read_csv(\"./data/x_train.csv\").to_numpy(), dtype=float)\n",
    "y_train = torch.tensor(pd.read_csv(\"./data/y_train.csv\").to_numpy(), dtype=float)\n",
    "\n",
    "X_test = torch.tensor(pd.read_csv(\"./data/x_test.csv\").to_numpy(), dtype=float)\n",
    "y_test = torch.tensor(pd.read_csv(\"./data/y_test.csv\").to_numpy(), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a218dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# INITIALIZE MODEL, LOSS, AND OPTIMIZER\n",
    "# -----------------------------\n",
    "\n",
    "# Create an instance of your model (a simple linear regression model here)\n",
    "# This model will learn a relationship like: y = w*x + b\n",
    "model = nn.Linear(in_features=X_train.shape[1], out_features=1, dtype=float)\n",
    "\n",
    "# Define the loss function (how we measure the model’s error)\n",
    "# nn.MSELoss() = Mean Squared Error → average of squared differences between predicted and actual values\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer — this updates model weights to reduce the loss\n",
    "# SGD = Stochastic Gradient Descent, a common optimization algorithm\n",
    "# model.parameters() = tells optimizer which parameters to update (weights & biases)\n",
    "# lr=0.01 = learning rate, controls how big a step we take each update\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be9f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/10000000], Loss: 381.0717\n",
      "Epoch [100/10000000], Loss: 98.1902\n",
      "Epoch [150/10000000], Loss: 54.8435\n",
      "Epoch [200/10000000], Loss: 37.4709\n",
      "Epoch [250/10000000], Loss: 26.7108\n",
      "Epoch [300/10000000], Loss: 19.4895\n",
      "Epoch [350/10000000], Loss: 14.5849\n",
      "Epoch [400/10000000], Loss: 11.2477\n",
      "Epoch [450/10000000], Loss: 8.9762\n",
      "Epoch [500/10000000], Loss: 7.4300\n",
      "Epoch [550/10000000], Loss: 6.3775\n",
      "Epoch [600/10000000], Loss: 5.6611\n",
      "Epoch [650/10000000], Loss: 5.1734\n",
      "Epoch [700/10000000], Loss: 4.8414\n",
      "Epoch [750/10000000], Loss: 4.6155\n",
      "Epoch [800/10000000], Loss: 4.4617\n",
      "Epoch [850/10000000], Loss: 4.3570\n",
      "Epoch [900/10000000], Loss: 4.2857\n",
      "Epoch [950/10000000], Loss: 4.2372\n",
      "Epoch [1000/10000000], Loss: 4.2041\n",
      "Epoch [1050/10000000], Loss: 4.1817\n",
      "Epoch [1100/10000000], Loss: 4.1664\n",
      "Epoch [1150/10000000], Loss: 4.1560\n",
      "Epoch [1200/10000000], Loss: 4.1489\n",
      "Epoch [1250/10000000], Loss: 4.1440\n",
      "Epoch [1300/10000000], Loss: 4.1408\n",
      "Epoch [1350/10000000], Loss: 4.1385\n",
      "Epoch [1400/10000000], Loss: 4.1370\n",
      "Epoch [1450/10000000], Loss: 4.1360\n",
      "Epoch [1500/10000000], Loss: 4.1353\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# TRAINING LOOP FOR A MODEL\n",
    "# -----------------------------\n",
    "\n",
    "# Set a small tolerance value — if the loss stops changing by more than this, we’ll stop training early\n",
    "tol = 1e-5\n",
    "\n",
    "# Set the maximum number of epochs (full passes through the dataset)\n",
    "# 1e7 = 10 million (a very large number, used here as an upper limit)\n",
    "epochs = int(1e7)\n",
    "\n",
    "# Store the previous loss value; start with infinity so any real loss will be smaller\n",
    "prev_loss = float(\"inf\")\n",
    "\n",
    "# Loop through each epoch (training iteration)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---- Forward pass ----\n",
    "    # Feed the training data (X_train) to the model to get predictions (outputs)\n",
    "    outputs = model(X_train)\n",
    "\n",
    "    # Calculate how far off the predictions are from the true labels (y_train)\n",
    "    # The 'criterion' defines the loss function (e.g., MSE, cross-entropy, etc.)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # ---- Backward pass & optimization ----\n",
    "    # Clear (reset) any gradients from the previous step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute new gradients for each model parameter based on the current loss\n",
    "    loss.backward()\n",
    "\n",
    "    # Update model parameters (weights and biases) using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # ---- Check progress ----\n",
    "    # Convert the loss (a PyTorch tensor) to a plain Python number\n",
    "    curr_loss = loss.item()\n",
    "\n",
    "    # Print the current epoch number and loss every 50 epochs to track progress\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {curr_loss:.4f}\")\n",
    "\n",
    "    # ---- Early stopping condition ----\n",
    "    # If the loss hasn’t changed much compared to the last epoch, stop training\n",
    "    if abs(curr_loss - prev_loss) <= tol:\n",
    "        break\n",
    "\n",
    "    # Save current loss as previous loss for the next iteration\n",
    "    prev_loss = curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68538be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffee925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model/model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d28500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4.2328\n",
      "Root Mean Squared Error (RMSE): 2.0574\n",
      "Mean Absolute Error (MAE): 1.6441\n",
      "R2 Score: 0.9889\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "\n",
    "y_test_flat, y_pred_flat = y_test.numpy().flatten(), y_pred.detach().numpy().flatten()\n",
    "\n",
    "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_flat, y_pred_flat)\n",
    "r2 = r2_score(y_test_flat, y_pred_flat)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee424fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
